%!TEX root = paper.tex
We first provide a brief introduction to the BitTorrent protocol, including defining the terminology associated with BitTorrent. We then summarize some results from PAC search that we require for our theoretical analysis. 

\subsection{The BitTorrent Protocol}

    The BitTorrent protocol \footnote{\url{http://bittorrent.org/beps/bep_0003.html}} is a mechanism for distributing files around a large number of computers in a peer-to-peer network. It was designed to allow many users to concurrently download files without demanding excessive bandwidth from any single machine. This is achieved by first partitioning a file into many \emph{pieces}. A node then downloads these pieces from many other nodes in the network and subsequently merges the pieces to recover the original file. Each piece of a file is small enough that, individually, they are easy to supply. The requesting node receives a \emph{torrent} of these small pieces that it can combine to form the desired file. When the requesting node receives a piece of the file it can also start to offer that piece to other nodes. Since pieces of popular files will reside on many nodes, BitTorrent also provides an inherent load balancing capability.

    In order to share data over BitTorrent, an author or publisher of a file must create a meta-data file called the \emph{.torrent file}. Each .torrent file contains (i) a list of the pieces that constitute the file, (ii)  the URL of the torrent's tracker, and (iii) an identifier for the torrent. This identifier, called the \emph{infohash}, is used to negotiate the download.

    A \emph{tracker} is a centralised server that monitors the sharing of data in the network. For every torrent a tracker is responsible for, the tracker keeps a list of the peers that are uploading or downloading the torrent's data. When a new node enters the network it can request a copy of this list from the tracker. The new node can then contact the nodes listed and start to request pieces. Nodes that are downloading or uploading data must periodically communicate with the tracker in order to keep the list up-to-date. We refer to the combination of the torrent's unique ID, i.e. the infohash, and the list of nodes participating in the torrent as the {\em tracking data}.
    
    The centralised nature of the tracker is a security weakness as attackers can attempt to disrupt the tracker. This weakness is well recognised by the BitTorrent community and several solutions have been adopted. The multi-tracker extension\footnote{\url{http://bittorrent.org/beps/bep_0012.html}} to the protocol allows torrent authors to list more than one tracker URL in the .torrent file. If one tracker fails, the node can attempt to contact a second and is therefore less affected by individual tracker failure. HTTP\footnote{\url{http://bittorrent.org/beps/bep_0017.html}} and FTP\footnote{\url{http://bittorrent.org/beps/bep_0019.html}} seeding extensions allow torrent authors to make their files available via a direct HTTP/FTP connection. If the trackers are unavailable then nodes can fall back to a more traditional form of direct downloading. Tracker exchange\footnote{\url{http://bittorrent.org/beps/bep_0028.html}} lets nodes share information on BitTorrent trackers. Using this extension, nodes can learn which trackers are the most popular or robust for a particular torrent. Each of these solutions provide additional security by replicating the centralised services. This tactic protects against accidental failure but can do little to prevent a coordinated attack. Each individual service remains susceptible to disruption.

    The peer exchange (PEX) \cite{Wu} extension enables node discovery without using a tracker. Peer exchange lets nodes share tracking data directly. There are several, independent, implementations of the peer exchange protocol\cite{Wu}, and each achieves the same goal. When two nodes, participating in a torrent, communicate with each other, they can optionally choose to exchange tracking data. Each node sends a list of other nodes that it knows to have recently joined or left that torrent. By doing this nodes are made aware of new nodes to contact and old nodes not to contact without needing to poll the tracker. Reducing traffic to the tracker means that it is less likely to become overloaded. If the tracker were to fail nodes can still successfully gather tracking data. PEX only works if a node is aware of at least one other node. It does not, therefore, remove the requirement for the tracker in the first place. Our BitTorrent modification in Section~\ref{sec:extension} uses the fact that if details of a single node can be discovered then details of other nodes can be shared using PEX.

    The distributed hash table (DHT) extension\footnote{\url{http://bittorrent.org/beps/bep_0005.html}} moves the tracking data from the tracker into a shared and distributed database. BitTorrent uses an implementation of a Kademlia DHT system\cite{maymounkov_kademlia:_2002} that enables nodes that are new to the network to retrieve a torrent's tracking data without requesting anything from a tracker. The DHT extension to the BitTorrent protocol successfully removes the requirement for a centralised tracking service, a single point of failure in the original protocol. Unfortunately, there are some side effects to this DHT implementation which may introduce new security concerns as well as potentially undermining some of the previously assumed benefits. For example, in \cite{Timpanaro2011} a Sybil attack, where many nodes are controlled by a single entity, is performed that successfully pollutes the DHT and manages to eclipse targeted torrents. Eclipsed torrents are effectively removed from the DHT by making them undiscoverable.

\subsection{Probably Approximately Correct Search}

    Probably approximately correct (PAC) search, introduced in \cite{Cox2009}, is an information retrieval mechanism that operates under a similar maxim to BitTorrent; let many machines do small amounts of work. PAC search is a system that enables full-text search over a document collection. The collection is randomly distributed around a network of nodes, each node holding a small fraction of the total collection in a local index. Documents are duplicated across nodes to provide redundancy. To perform a search, a node issues a query to a randomly sampled set of nodes. Each node applies the query to its local index and returns any matching documents. The results from all queried nodes are collated and duplicate results removed. If the resulting document set does not meet the search requirements the query can be re-issued to a newly sampled set of nodes.

    PAC search distributes text-search tasks across multiple nodes and so reduces the workload of each node. PAC can scale to accommodate large collections, as additional nodes can be easily added to the network\cite{Cox2009}. Documents can be added and removed from the collection without requiring any complex re-partitioning. It achieves these goals at the expense of accuracy and efficiency\cite{Asthana2011,Cox}. In comparison to a deterministic full-text search system, PAC search is unlikely to be able to return the exact same results. Given the overheads introduced for network communications, a PAC search request is also likely to take longer to return and may require more bandwidth.

    There are three factors that influence the ability of a PAC search system to correctly retrieve a document, $d_i$, namely (i) the number of nodes in the network, $n$, (ii) the number of nodes that index the document, $r_i$, and (iii) the number of nodes contacted per query, $z$. A search over a collection of documents distributed across $n$ nodes involves a node querying $z$ other nodes. Each of the $z$ nodes will perform a search for the document across their local index and return any matching results. A document can only appear in PAC search results if it is present in the local index of at least one of the $z$ nodes that were queried. From \cite{Cox2009} the probability, $P(d_i)$, that document $d_i$ is present in at least one of the $z$ local indexes is given by:
    
    \begin{equation}
        P(d_i) = 1 - (1-\frac{r_i}{n})^{z}
        \label{eq:prob_find_non_uniform_distribution}
    \end{equation}

    In the context of BitTorrent, we are performing a \emph{known item} search, where we are searching for one and only one document, uniquely identified by its infohash. As such, broader definitions of accuracy introduced in \cite{Asthana2011,Cox} are not relevant and Eqn~(\ref{eq:prob_find_non_uniform_distribution}) provides the probability of a successful search. In Section~\ref{sec:measurement} we observe 5.4 million unique nodes in the BitTorrent network. Using this value and Eqn~(\ref{eq:prob_find_non_uniform_distribution}) we can calculate the number of nodes that a document needs to be replicated over in order to achieve a given accuracy. For example, if $P(d_i)=0.8$ and $z=100$ then we would require a document to be replicated across 86,214 nodes, i.e. 1.6\% of the network. If we were to contact more nodes per query then our replication requirement decreases, for example $z=500$ requires a document to be replicated across 17,354 nodes (0.32\%).

    Information retrieval in unstructured networks is a well-researched area. In \cite{Cohen2002} the authors study the performance of search using different replication strategies; uniform, proportional and square-root. They conclude that uniform and proportional strategies, where documents are distributed uniformly or according to their popularity respectively, require the same expected search length, i.e. the average number of nodes that need to be contacted in order to find documents is the same. Square-root replication, where documents are distributed over a number of nodes proportional to the square root of their popularity, performs optimally, i.e. has the lowest expected search length. In \cite{Terpstra} the authors introduce BubbleStorm, a system for search over unstructured peer-to-peer networks, very similar to PAC search. BubbleStorm provides a gossiping algorithm that is very resilient to network churn and large numbers of node failure. 

    In this paper we do not consider the issue of peer sampling, that is, we assume that a PAC search client is capable of taking a uniformly random sample of nodes from the network. Methods that achieve this goal are numerous. BubbleStorm uses local-view gossiping to achieve this. In \cite{Chawathe2003} the authors consider using random walks over an unstructured networks to replace flooding found in systems such as Gnutella. In \cite{bortnikov_brahms:_2009} the authors introduce Brahms, a system for random peer sampling in unstructured networks that uses another gossip-based protocol. Brahms also provides security measures for sampling in a Byzantine environment.
